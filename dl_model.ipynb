{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a43ae4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92cada2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6be591f46f489da956f08a03bd02cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3452e1888d4e499815a9473a22f7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)on_pytorch_model.bin:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2e395d8f254c56b2008c914ad07805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe86a22294fc4d5887ef6a33ffdbded2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)on_pytorch_model.bin:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d7151466cd42a4bc231d5f137a4abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['model-56830/model_index.json',\n",
       " 'model-56830/tokenizer/tokenizer_config.json',\n",
       " 'model-56830/tokenizer/special_tokens_map.json',\n",
       " 'model-56830/tokenizer/merges.txt',\n",
       " 'model-56830/tokenizer/vocab.json',\n",
       " 'model-56830/scheduler/scheduler_config.json',\n",
       " 'model-56830/text_encoder/config.json',\n",
       " 'model-56830/text_encoder/pytorch_model.bin',\n",
       " 'model-56830/README.md',\n",
       " 'model-56830/unet/config.json',\n",
       " 'model-56830/unet/diffusion_pytorch_model.bin',\n",
       " 'model-56830/safety_checker/config.json',\n",
       " 'model-56830/safety_checker/pytorch_model.bin',\n",
       " 'model-56830/.gitattributes',\n",
       " 'model-56830/feature_extractor/preprocessor_config.json',\n",
       " 'model-56830/vae/config.json',\n",
       " 'model-56830/vae/diffusion_pytorch_model.bin']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "import random\n",
    "\n",
    "HF_MODEL_ID=\"lambdalabs/sd-pokemon-diffusers\"\n",
    "HF_TOKEN=\"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\" # your hf token: https://huggingface.co/settings/tokens\n",
    "assert len(HF_TOKEN) > 0, \"Please set HF_TOKEN to your huggingface token. You can find it here: https://huggingface.co/settings/tokens\"\n",
    "\n",
    "# download snapshot\n",
    "snapshot_dir = snapshot_download(repo_id=HF_MODEL_ID,use_auth_token=HF_TOKEN)\n",
    "\n",
    "# create model dir\n",
    "model_tar = Path(f\"model-{random.getrandbits(16)}\")\n",
    "model_tar.mkdir(exist_ok=True)\n",
    "\n",
    "# copy snapshot to model dir\n",
    "copy_tree(snapshot_dir, str(model_tar))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d8db11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-56830/code/.DS_Store',\n",
       " 'model-56830/code/requirements.txt',\n",
       " 'model-56830/code/inference.py']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy code/ to model dir\n",
    "copy_tree(\"code/\", str(model_tar.joinpath(\"code\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3022d70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_index.json\n",
      "tokenizer\n",
      "code\n",
      "scheduler\n",
      "text_encoder\n",
      "README.md\n",
      "unet\n",
      "safety_checker\n",
      ".gitattributes\n",
      "feature_extractor\n",
      "vae\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "# helper to create the model.tar.gz\n",
    "def compress(tar_dir=None,output_file=\"model.tar.gz\"):\n",
    "    parent_dir=os.getcwd()\n",
    "    os.chdir(tar_dir)\n",
    "    with tarfile.open(os.path.join(parent_dir, output_file), \"w:gz\") as tar:\n",
    "        for item in os.listdir('.'):\n",
    "          print(item)\n",
    "          tar.add(item, arcname=item)\n",
    "    os.chdir(parent_dir)\n",
    "\n",
    "compress(str(model_tar))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ec01b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_index.json\n",
      "tokenizer/\n",
      "tokenizer/merges.txt\n",
      "tokenizer/special_tokens_map.json\n",
      "tokenizer/tokenizer_config.json\n",
      "tokenizer/vocab.json\n",
      "code/\n",
      "code/.DS_Store\n",
      "code/inference.py\n",
      "code/requirements.txt\n",
      "scheduler/\n",
      "scheduler/scheduler_config.json\n",
      "text_encoder/\n",
      "text_encoder/config.json\n",
      "text_encoder/pytorch_model.bin\n",
      "README.md\n",
      "unet/\n",
      "unet/config.json\n",
      "unet/diffusion_pytorch_model.bin\n",
      "safety_checker/\n",
      "safety_checker/config.json\n",
      "safety_checker/pytorch_model.bin\n",
      ".gitattributes\n",
      "feature_extractor/\n",
      "feature_extractor/preprocessor_config.json\n",
      "vae/\n",
      "vae/config.json\n",
      "vae/diffusion_pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!tar -tf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4eecfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
